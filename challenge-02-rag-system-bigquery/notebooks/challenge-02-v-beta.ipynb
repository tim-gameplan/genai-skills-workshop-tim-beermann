{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge 2 | RAG"
      ],
      "metadata": {
        "id": "WuPI69Res4ZG"
      },
      "id": "WuPI69Res4ZG"
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-ba43f2730b93\"\n",
        "# The exact email from your error log\n",
        "SERVICE_ACCOUNT = \"bqcx-281600971548-ntww@gcp-sa-bigquery-condel.iam.gserviceaccount.com\"\n",
        "\n",
        "print(f\"--- Force-Granting Vertex AI User Role to: {SERVICE_ACCOUNT} ---\")\n",
        "\n",
        "# Construct the gcloud command\n",
        "# We use ! (bang) syntax to run it directly in the shell for reliability\n",
        "command = f\"gcloud projects add-iam-policy-binding {PROJECT_ID} --member='serviceAccount:{SERVICE_ACCOUNT}' --role='roles/aiplatform.user'\"\n",
        "\n",
        "# Run it using the shell magic\n",
        "get_ipython().system(command)\n",
        "\n",
        "print(\"\\nâ³ Waiting 60 seconds for permissions to propagate...\")\n",
        "print(\"Do not skip this wait. IAM needs time to sync across Google's global servers.\")\n",
        "time.sleep(60)\n",
        "print(\"âœ… Ready to try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOHRvev1xoxD",
        "outputId": "b4bbec95-dee3-4bc5-a3e7-c5362104100e"
      },
      "id": "OOHRvev1xoxD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Force-Granting Vertex AI User Role to: bqcx-281600971548-ntww@gcp-sa-bigquery-condel.iam.gserviceaccount.com ---\n",
            "Updated IAM policy for project [qwiklabs-gcp-03-ba43f2730b93].\n",
            "bindings:\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@gcp-sa-vertex-nb.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.colabServiceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@gcp-sa-aiplatform-vm.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.notebookServiceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@gcp-sa-aiplatform.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:bqcx-281600971548-ntww@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
            "  role: roles/aiplatform.user\n",
            "- members:\n",
            "  - serviceAccount:qwiklabs-gcp-03-ba43f2730b93@qwiklabs-gcp-03-ba43f2730b93.iam.gserviceaccount.com\n",
            "  role: roles/bigquery.admin\n",
            "- members:\n",
            "  - serviceAccount:281600971548@cloudbuild.gserviceaccount.com\n",
            "  role: roles/cloudbuild.builds.builder\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@gcp-sa-cloudbuild.iam.gserviceaccount.com\n",
            "  role: roles/cloudbuild.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@compute-system.iam.gserviceaccount.com\n",
            "  role: roles/compute.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@gcp-sa-dataform.iam.gserviceaccount.com\n",
            "  role: roles/dataform.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:281600971548-compute@developer.gserviceaccount.com\n",
            "  - serviceAccount:281600971548@cloudservices.gserviceaccount.com\n",
            "  role: roles/editor\n",
            "- members:\n",
            "  - serviceAccount:service-281600971548@gcp-sa-modelarmor.iam.gserviceaccount.com\n",
            "  role: roles/modelarmor.serviceAgent\n",
            "- members:\n",
            "  - serviceAccount:admiral@qwiklabs-services-prod.iam.gserviceaccount.com\n",
            "  - serviceAccount:qwiklabs-gcp-03-ba43f2730b93@qwiklabs-gcp-03-ba43f2730b93.iam.gserviceaccount.com\n",
            "  - user:student-02-ca6bd4cdd47b@qwiklabs.net\n",
            "  role: roles/owner\n",
            "- members:\n",
            "  - serviceAccount:qwiklabs-gcp-03-ba43f2730b93@qwiklabs-gcp-03-ba43f2730b93.iam.gserviceaccount.com\n",
            "  role: roles/storage.admin\n",
            "- members:\n",
            "  - user:student-02-ca6bd4cdd47b@qwiklabs.net\n",
            "  role: roles/viewer\n",
            "etag: BwZE_gfft7c=\n",
            "version: 1\n",
            "\n",
            "â³ Waiting 60 seconds for permissions to propagate...\n",
            "Do not skip this wait. IAM needs time to sync across Google's global servers.\n",
            "âœ… Ready to try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe:\n",
        "# uuid: E11F9AD6-D645-4C79-BBED-BA8FC8234625\n",
        "# output_variable:\n",
        "# config_str:\n",
        "\n",
        "import google.colabsqlviz.explore_dataframe as _vizcell\n",
        "_vizcell.explore_dataframe(df_or_df_name='', uuid='E11F9AD6-D645-4C79-BBED-BA8FC8234625')"
      ],
      "metadata": {
        "colab_type": "viz",
        "id": "Y2IP7ZCBvWFT"
      },
      "id": "Y2IP7ZCBvWFT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from google.cloud import bigquery\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-ba43f2730b93\"\n",
        "REGION = \"us-central1\"\n",
        "DATASET_ID = \"aurora_bay_rag\"\n",
        "CONNECTION_ID = \"us-central1.vertex-ai-conn\"\n",
        "CSV_URI = \"gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\"\n",
        "\n",
        "client = bigquery.Client(project=PROJECT_ID, location=REGION)\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "def run_query(sql):\n",
        "    try:\n",
        "        job = client.query(sql, location=REGION)\n",
        "        result = job.result()\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"ðŸš€ Starting Challenge 2 Solution (Final Fix)...\")\n",
        "\n",
        "# --- STEP 1: LOAD DATA WITH EXPLICIT SCHEMA ---\n",
        "print(f\"--- 1. Loading Data into {DATASET_ID} ---\")\n",
        "dataset = bigquery.Dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
        "dataset.location = REGION\n",
        "client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "table_ref = client.dataset(DATASET_ID).table(\"faqs_raw\")\n",
        "\n",
        "# FIX: Define the schema manually to guarantee column names\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=[\n",
        "        bigquery.SchemaField(\"question\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"answer\", \"STRING\"),\n",
        "    ],\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        "    skip_leading_rows=1, # Skip the header row in the file\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
        ")\n",
        "\n",
        "load_job = client.load_table_from_uri(CSV_URI, table_ref, job_config=job_config)\n",
        "load_job.result()\n",
        "print(f\"âœ… Loaded {load_job.output_rows} rows from GCS.\")\n",
        "\n",
        "# --- STEP 2: CREATE EMBEDDING MODEL ---\n",
        "print(f\"--- 2. Creating Remote Model (Connection: {CONNECTION_ID}) ---\")\n",
        "create_model_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{CONNECTION_ID}`\n",
        "OPTIONS (ENDPOINT = 'text-embedding-004');\n",
        "\"\"\"\n",
        "run_query(create_model_sql)\n",
        "\n",
        "# Give it 5 seconds to propagate\n",
        "time.sleep(5)\n",
        "\n",
        "# --- STEP 3: GENERATE EMBEDDINGS ---\n",
        "print(\"--- 3. Generating Vectors (Index) ---\")\n",
        "# Now that we forced the schema, 'question' and 'answer' are guaranteed to exist\n",
        "index_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.faq_vectors` AS\n",
        "SELECT\n",
        "  base.question,\n",
        "  base.answer,\n",
        "  emb.ml_generate_embedding_result as embedding\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "  (\n",
        "    SELECT\n",
        "      question,\n",
        "      answer,\n",
        "      CONCAT('Question: ', question, ' Answer: ', answer) as content\n",
        "    FROM `{PROJECT_ID}.{DATASET_ID}.faqs_raw`\n",
        "  )\n",
        ") as emb\n",
        "JOIN `{PROJECT_ID}.{DATASET_ID}.faqs_raw` as base\n",
        "ON emb.question = base.question;\n",
        "\"\"\"\n",
        "run_query(index_sql)\n",
        "print(\"âœ… Embeddings generated successfully.\")\n",
        "\n",
        "# --- STEP 4: RAG CHATBOT ---\n",
        "def ask_aurora_bay(user_query):\n",
        "    print(f\"\\nUser Query: '{user_query}'\")\n",
        "\n",
        "    # A. Search\n",
        "    search_sql = f\"\"\"\n",
        "    SELECT\n",
        "        base.answer,\n",
        "        (1 - distance) AS similarity_score\n",
        "    FROM VECTOR_SEARCH(\n",
        "        TABLE `{PROJECT_ID}.{DATASET_ID}.faq_vectors`,\n",
        "        'embedding',\n",
        "        (\n",
        "            SELECT ml_generate_embedding_result, '{user_query}' AS query\n",
        "            FROM ML.GENERATE_EMBEDDING(\n",
        "                MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "                (SELECT '{user_query}' AS content)\n",
        "            )\n",
        "        ),\n",
        "        top_k => 1\n",
        "    )\n",
        "    ORDER BY similarity_score DESC;\n",
        "    \"\"\"\n",
        "    results = run_query(search_sql)\n",
        "\n",
        "    # B. Generate\n",
        "    if results:\n",
        "        for row in results:\n",
        "            if row.similarity_score > 0.4:\n",
        "                prompt = f\"\"\"\n",
        "                You are the Aurora Bay Town Clerk. Answer using this official info ONLY.\n",
        "                INFO: {row.answer}\n",
        "                QUESTION: {user_query}\n",
        "                \"\"\"\n",
        "                model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
        "                response = model.generate_content(prompt)\n",
        "                return f\"Aurora Bot: {response.text}\"\n",
        "\n",
        "    return \"Aurora Bot: Sorry, I couldn't find that in the town records.\"\n",
        "\n",
        "# --- STEP 5: TEST ---\n",
        "print(ask_aurora_bay(\"Where is the town hall?\"))\n",
        "print(ask_aurora_bay(\"Who do I call for wildlife issues?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0basrLAy7s0",
        "outputId": "ce26743e-0563-415d-92e3-fc17d7f6cf13"
      },
      "id": "X0basrLAy7s0",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting Challenge 2 Solution (Final Fix)...\n",
            "--- 1. Loading Data into aurora_bay_rag ---\n",
            "âœ… Loaded 50 rows from GCS.\n",
            "--- 2. Creating Remote Model (Connection: us-central1.vertex-ai-conn) ---\n",
            "--- 3. Generating Vectors (Index) ---\n",
            "âœ… Embeddings generated successfully.\n",
            "\n",
            "User Query: 'Where is the town hall?'\n",
            "Aurora Bot: Sorry, I couldn't find that in the town records.\n",
            "\n",
            "User Query: 'Who do I call for wildlife issues?'\n",
            "Aurora Bot: Sorry, I couldn't find that in the town records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DEBUGGING TOOL ---\n",
        "\n",
        "# 1. SEE WHAT IS IN THE DB\n",
        "print(\"--- ðŸ”Ž INSPECTING KNOWLEDGE BASE (Top 5 Entries) ---\")\n",
        "sql_peek = f\"\"\"\n",
        "SELECT question, answer\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.faqs_raw`\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "rows = run_query(sql_peek)\n",
        "for row in rows:\n",
        "    print(f\"Q: {row.question}\")\n",
        "    print(f\"A: {row.answer[:50]}...\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "# 2. RUN A RAW SEARCH (No Threshold)\n",
        "def debug_search(user_query):\n",
        "    print(f\"\\n--- ðŸ§ª DEBUG SEARCH FOR: '{user_query}' ---\")\n",
        "\n",
        "    search_sql = f\"\"\"\n",
        "    SELECT\n",
        "        base.question,\n",
        "        base.answer,\n",
        "        distance, -- The raw distance score (Lower is better)\n",
        "        (1 - distance) AS similarity -- Calculated similarity\n",
        "    FROM VECTOR_SEARCH(\n",
        "        TABLE `{PROJECT_ID}.{DATASET_ID}.faq_vectors`,\n",
        "        'embedding',\n",
        "        (\n",
        "            SELECT ml_generate_embedding_result, '{user_query}' AS query\n",
        "            FROM ML.GENERATE_EMBEDDING(\n",
        "                MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "                (SELECT '{user_query}' AS content)\n",
        "            )\n",
        "        ),\n",
        "        top_k => 3\n",
        "    )\n",
        "    ORDER BY distance ASC; -- Show closest matches first\n",
        "    \"\"\"\n",
        "    results = run_query(search_sql)\n",
        "\n",
        "    for row in results:\n",
        "        print(f\"Match: {row.question}\")\n",
        "        print(f\"Score: {row.similarity:.4f} (Distance: {row.distance:.4f})\")\n",
        "        print(f\"Answer: {row.answer[:100]}...\\n\")\n",
        "\n",
        "# Run the debug searches\n",
        "debug_search(\"town hall\")\n",
        "debug_search(\"wildlife\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0YCo8kXza2y",
        "outputId": "49cd2a1a-672d-4a36-f64b-30494f34574f"
      },
      "id": "X0YCo8kXza2y",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ðŸ”Ž INSPECTING KNOWLEDGE BASE (Top 5 Entries) ---\n",
            "Q: When was Aurora Bay founded?\n",
            "A: Aurora Bay was founded in 1901 by a group of fur t...\n",
            "--------------------\n",
            "Q: What is the population of Aurora Bay?\n",
            "A: Aurora Bay has a population of approximately 3,200...\n",
            "--------------------\n",
            "Q: Where is the Aurora Bay Town Hall located?\n",
            "A: The Town Hall is located at 100 Harbor View Road, ...\n",
            "--------------------\n",
            "Q: Who is the current mayor of Aurora Bay?\n",
            "A: The current mayor is Linda Greenwood, elected in 2...\n",
            "--------------------\n",
            "Q: What are the primary industries in Aurora Bay?\n",
            "A: The primary industries include commercial fishing,...\n",
            "--------------------\n",
            "\n",
            "--- ðŸ§ª DEBUG SEARCH FOR: 'town hall' ---\n",
            "Match: When are the town council meetings held?\n",
            "Score: 0.1379 (Distance: 0.8621)\n",
            "Answer: Town council meetings are held every second Tuesday of the month at 6 PM in the Town Hall conference...\n",
            "\n",
            "Match: Where is the Aurora Bay Town Hall located?\n",
            "Score: 0.0612 (Distance: 0.9388)\n",
            "Answer: The Town Hall is located at 100 Harbor View Road, in the center of Aurora Bay, close to the main har...\n",
            "\n",
            "Match: How can I volunteer in community events?\n",
            "Score: 0.0132 (Distance: 0.9868)\n",
            "Answer: You can sign up through the Community Centerâ€™s volunteer portal or attend volunteer meetings announc...\n",
            "\n",
            "\n",
            "--- ðŸ§ª DEBUG SEARCH FOR: 'wildlife' ---\n",
            "Match: Where is the best place for whale watching?\n",
            "Score: -0.1160 (Distance: 1.1160)\n",
            "Answer: The Aurora Bay Harbor area offers whale watching tours, especially during spring and summer when hum...\n",
            "\n",
            "Match: What types of recreation are available in Aurora Bay?\n",
            "Score: -0.1418 (Distance: 1.1418)\n",
            "Answer: Popular activities include fishing, kayaking, hiking in the nearby forests, and northern lights view...\n",
            "\n",
            "Match: Are there guided tours for Northern Lights viewing?\n",
            "Score: -0.1483 (Distance: 1.1483)\n",
            "Answer: Yes. Several local outfitters offer guided night tours outside town lights for optimal aurora boreal...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: RAG CHATBOT (FIXED MODEL NAME) ---\n",
        "def ask_aurora_bay(user_query):\n",
        "    print(f\"\\nUser Query: '{user_query}'\")\n",
        "\n",
        "    # A. Search\n",
        "    search_sql = f\"\"\"\n",
        "    SELECT\n",
        "        base.answer,\n",
        "        (1 - distance) AS similarity_score\n",
        "    FROM VECTOR_SEARCH(\n",
        "        TABLE `{PROJECT_ID}.{DATASET_ID}.faq_vectors`,\n",
        "        'embedding',\n",
        "        (\n",
        "            SELECT ml_generate_embedding_result, '{user_query}' AS query\n",
        "            FROM ML.GENERATE_EMBEDDING(\n",
        "                MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "                (SELECT '{user_query}' AS content)\n",
        "            )\n",
        "        ),\n",
        "        top_k => 1\n",
        "    )\n",
        "    ORDER BY similarity_score DESC;\n",
        "    \"\"\"\n",
        "    results = run_query(search_sql)\n",
        "\n",
        "    # B. Generate\n",
        "    if results:\n",
        "        for row in results:\n",
        "            print(f\"   --> Match Score: {row.similarity_score:.4f} (Accepted)\")\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You are the Aurora Bay Town Clerk. Answer using this official info ONLY.\n",
        "            INFO: {row.answer}\n",
        "            QUESTION: {user_query}\n",
        "            \"\"\"\n",
        "\n",
        "            # FIX: Changed 'gemini-2.5-flash-001' to 'gemini-1.5-flash'\n",
        "            # This points to the latest stable version automatically\n",
        "            model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "            response = model.generate_content(prompt)\n",
        "            return f\"Aurora Bot: {response.text}\"\n",
        "\n",
        "    return \"Aurora Bot: Sorry, I couldn't find that in the town records.\"\n",
        "\n",
        "# --- STEP 5: TEST ---\n",
        "print(ask_aurora_bay(\"Where is the town hall located?\"))\n",
        "print(ask_aurora_bay(\"Who is the mayor?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wenHVbGI0L4r",
        "outputId": "2551460c-a31f-4a90-f606-ee2ed0951296"
      },
      "id": "wenHVbGI0L4r",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User Query: 'Where is the town hall located?'\n",
            "   --> Match Score: 0.2015 (Accepted)\n",
            "Aurora Bot: I apologize, but the provided information does not specify the location of the Town Hall. It only states that town council meetings are held in the Town Hall conference room.\n",
            "\n",
            "User Query: 'Who is the mayor?'\n",
            "   --> Match Score: 0.0248 (Accepted)\n",
            "Aurora Bot: Linda Greenwood.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: RAG CHATBOT (HIGH ACCURACY / TOP-3) ---\n",
        "def ask_aurora_bay(user_query):\n",
        "    print(f\"\\nUser Query: '{user_query}'\")\n",
        "\n",
        "    # A. Search (Get Top 3 matches instead of 1)\n",
        "    search_sql = f\"\"\"\n",
        "    SELECT\n",
        "        base.answer,\n",
        "        (1 - distance) AS similarity_score\n",
        "    FROM VECTOR_SEARCH(\n",
        "        TABLE `{PROJECT_ID}.{DATASET_ID}.faq_vectors`,\n",
        "        'embedding',\n",
        "        (\n",
        "            SELECT ml_generate_embedding_result, '{user_query}' AS query\n",
        "            FROM ML.GENERATE_EMBEDDING(\n",
        "                MODEL `{PROJECT_ID}.{DATASET_ID}.embedding_model`,\n",
        "                (SELECT '{user_query}' AS content)\n",
        "            )\n",
        "        ),\n",
        "        top_k => 3  -- <--- INCREASED TO 3\n",
        "    )\n",
        "    ORDER BY similarity_score DESC;\n",
        "    \"\"\"\n",
        "    results = run_query(search_sql)\n",
        "\n",
        "    # B. Compile Context\n",
        "    if results:\n",
        "        # Combine all 3 answers into one big block of text\n",
        "        context_blob = \"\"\n",
        "        for row in results:\n",
        "            print(f\"   --> Found Context (Score: {row.similarity_score:.4f}): {row.answer[:50]}...\")\n",
        "            context_blob += f\"- {row.answer}\\n\"\n",
        "\n",
        "        # C. Generate (Gemini)\n",
        "        # We give Gemini all 3 facts and ask it to pick the right one\n",
        "        prompt = f\"\"\"\n",
        "        You are the Aurora Bay Town Clerk.\n",
        "        Use the provided KNOWLEDGE BASE to answer the user's question.\n",
        "        If the answer is not in the Knowledge Base, say \"I don't know.\"\n",
        "\n",
        "        KNOWLEDGE BASE:\n",
        "        {context_blob}\n",
        "\n",
        "        USER QUESTION: {user_query}\n",
        "        \"\"\"\n",
        "\n",
        "        # Sticking to the stable model name\n",
        "        model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        return f\"Aurora Bot: {response.text}\"\n",
        "\n",
        "    return \"Aurora Bot: Sorry, I couldn't find that in the town records.\"\n",
        "\n",
        "# --- STEP 5: TEST AGAIN ---\n",
        "print(ask_aurora_bay(\"Where is the town hall located?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTGL___O09Lt",
        "outputId": "494cc65f-3219-421c-80dc-0b750d5cef0b"
      },
      "id": "YTGL___O09Lt",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User Query: 'Where is the town hall located?'\n",
            "   --> Found Context (Score: 0.2015): Town council meetings are held every second Tuesda...\n",
            "   --> Found Context (Score: 0.1612): The Town Hall is located at 100 Harbor View Road, ...\n",
            "   --> Found Context (Score: 0.0568): Building permit applications can be obtained at th...\n",
            "Aurora Bot: The Town Hall is located at 100 Harbor View Road, in the center of Aurora Bay, close to the main harbor.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-02-ca6bd4cdd47b (Dec 2, 2025, 2:11:18â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}