{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8FwyYiNZtFr"
      },
      "source": [
        "# Challenge Three: Prompt Engineering with Automated Testing\n",
        "\n",
        "**Objective:** Build and validate two Gemini-powered functions using unit testing and comprehensive LLM evaluation.\n",
        "\n",
        "## What You'll Build\n",
        "\n",
        "1. **Classification Function** - Categorizes citizen inquiries into specific departments\n",
        "2. **Social Media Generator** - Creates official town posts for various topics\n",
        "\n",
        "## Two-Model Architecture\n",
        "\n",
        "This challenge uses **two different models** working together:\n",
        "\n",
        "```\n",
        "MODEL 1: Gemini 2.5 Flash (Generator)\n",
        "    Role: Generate responses to user queries\n",
        "    Used by: classify_inquiry(), generate_social_post()\n",
        "    Cost: ~$0.075 per 1M input tokens\n",
        "    \n",
        "         â†“ [generates output]\n",
        "         \n",
        "MODEL 2: Vertex AI Evaluation Judge (Evaluator)\n",
        "    Role: Score the quality of Model 1's outputs\n",
        "    Used by: EvalTask with model-based metrics\n",
        "    Model: Likely Gemini Pro or specialized judge model\n",
        "    Cost: Included in evaluation service\n",
        "```\n",
        "\n",
        "## Testing Strategy\n",
        "\n",
        "### 1. Unit Tests (pytest)\n",
        "- **Best for:** Deterministic outputs with exact answers\n",
        "- **Use case:** Classification (must return specific category)\n",
        "- **Speed:** Fast, Cost:** Free\n",
        "\n",
        "### 2. LLM Evaluation (Computed + Model-Based Metrics)\n",
        "- **Best for:** Creative outputs with variable results\n",
        "- **Use case:** Social media posts (different each time)\n",
        "- **Metrics:**\n",
        "  - **Computed metrics:** Reference-based, deterministic (BLEU, ROUGE)\n",
        "  - **Model-based metrics:** Semantic evaluation by judge LLM (coherence, safety, fluency)\n",
        "\n",
        "### 3. Prompt Comparison (Requirement #5)\n",
        "- **Purpose:** Compare different prompt strategies scientifically\n",
        "- **Method:** Evaluate multiple prompt variants on same task\n",
        "- **Output:** Data-driven recommendation for best prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Y3nWqPZtFs"
      },
      "source": [
        "## Cell 1: Installation & Runtime Configuration\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "**Libraries being installed:**\n",
        "\n",
        "1. **pytest** - Unit testing framework\n",
        "2. **google-cloud-aiplatform[evaluation]** - Vertex AI SDK with evaluation extras\n",
        "\n",
        "**Why the kernel restart?**\n",
        "\n",
        "Python caches imported modules in memory. After upgrading libraries, the kernel shutdown forces a clean reload.\n",
        "\n",
        "**Expected behavior:** The session will crash and restart. Continue with Cell 2 after restart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5-k_fX_ZtFs",
        "outputId": "6b5a730c-53d3-47e3-9c45-b484bd5cdd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Requirements\n",
            "------------------------------------------------------------\n",
            "Installing pytest for unit testing...\n",
            "Installing Vertex AI SDK with evaluation library...\n",
            "\n",
            "Libraries installed successfully.\n",
            "\n",
            "RESTARTING KERNEL TO LOAD NEW LIBRARIES\n",
            "The session will crash/restart momentarily.\n",
            "After restart, continue with Cell 2.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "print(\"Installing Requirements\")\n",
        "print(\"-\" * 60)\n",
        "print(\"Installing pytest for unit testing...\")\n",
        "print(\"Installing Vertex AI SDK with evaluation library...\")\n",
        "print()\n",
        "\n",
        "!pip install --upgrade --quiet pytest google-cloud-aiplatform[evaluation]\n",
        "\n",
        "import IPython\n",
        "import time\n",
        "\n",
        "print(\"Libraries installed successfully.\")\n",
        "print()\n",
        "print(\"RESTARTING KERNEL TO LOAD NEW LIBRARIES\")\n",
        "print(\"The session will crash/restart momentarily.\")\n",
        "print(\"After restart, continue with Cell 2.\")\n",
        "print()\n",
        "\n",
        "time.sleep(2)\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrRuiaI3ZtFt"
      },
      "source": [
        "## Cell 2: Function Definitions\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "**Configuration:**\n",
        "- `PROJECT_ID`: Your Google Cloud project (MUST UPDATE THIS)\n",
        "- `MODEL_NAME`: gemini-2.5-flash (Model 1 - Generator)\n",
        "\n",
        "**Function 1: classify_inquiry()**\n",
        "\n",
        "Purpose: Route citizen questions to correct department\n",
        "\n",
        "Categories: Employment | General Information | Emergency Services | Tax Related\n",
        "\n",
        "**Function 2: generate_social_post()**\n",
        "\n",
        "Purpose: Create official town social media posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrFzZHMpZtFt",
        "outputId": "fa78e885-644a-4a3a-8398-91304055ba39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
            "  from google.cloud.aiplatform.utils import gcs_utils\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function Definitions\n",
            "============================================================\n",
            "Project: qwiklabs-gcp-03-ba43f2730b93\n",
            "Model: gemini-2.5-flash\n",
            "\n",
            "Functions defined successfully.\n",
            "Next: Run Cell 3 to create test file\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "from vertexai.evaluation import EvalTask\n",
        "import pytest\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-ba43f2730b93\"\n",
        "REGION = \"us-central1\"\n",
        "MODEL_NAME = \"gemini-2.5-flash\"\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "# MODEL 1: The Generator (being tested)\n",
        "model = GenerativeModel(MODEL_NAME)\n",
        "\n",
        "print(\"Function Definitions\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Project: {PROJECT_ID}\")\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print()\n",
        "\n",
        "def classify_inquiry(user_question: str) -> str:\n",
        "    \"\"\"\n",
        "    Classifies citizen inquiry into one of four categories.\n",
        "\n",
        "    Categories: Employment, General Information, Emergency Services, Tax Related\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a classification system for the town of Aurora Bay.\n",
        "\n",
        "    Classify the following question into exactly one of these categories:\n",
        "    [Employment, General Information, Emergency Services, Tax Related]\n",
        "\n",
        "    RULES:\n",
        "    - Return ONLY the category name\n",
        "    - Do not add punctuation or explanations\n",
        "\n",
        "    Question: {user_question}\n",
        "    Category:\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip().replace(\".\", \"\")\n",
        "\n",
        "def generate_social_post(topic: str, platform: str = \"Twitter\") -> str:\n",
        "    \"\"\"\n",
        "    Generates official social media post for Aurora Bay.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are the social media manager for the town of Aurora Bay.\n",
        "\n",
        "    Write a short {platform} post about: {topic}\n",
        "\n",
        "    REQUIREMENTS:\n",
        "    - Tone: Official but friendly and helpful\n",
        "    - Length: Under 280 characters\n",
        "    - Include exactly ONE hashtag\n",
        "    - Be informative and actionable\n",
        "\n",
        "    EXAMPLES:\n",
        "    - Snow emergency declared. Parking ban 8pm-6am. Check aurora.gov for updates. #AuroraBay\n",
        "    - Libraries closed Monday for MLK Day. Digital services available 24/7. #AuroraBay\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "print(\"Functions defined successfully.\")\n",
        "print(\"Next: Run Cell 3 to create test file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyhydC7KZtFt"
      },
      "source": [
        "## Cell 3: Unit Test File Creation\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "**The %%writefile Magic Command:** Writes cell content to test_challenge.py on disk\n",
        "\n",
        "**Test Coverage:**\n",
        "- 5 classification tests (one per category + edge cases)\n",
        "- 3 social media tests (format validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvPp4yh3ZtFt",
        "outputId": "e72abc5e-4c0e-4538-8243-445ed1da6c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_challenge.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_challenge.py\n",
        "\"\"\"\n",
        "Unit tests for Aurora Bay functions.\n",
        "Run with: pytest -v test_challenge.py\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "import vertexai\n",
        "\n",
        "PROJECT_ID = \"YOUR_PROJECT_ID\"  # TODO: Update\n",
        "REGION = \"us-central1\"\n",
        "MODEL_NAME = \"gemini-2.5-flash\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "model = GenerativeModel(MODEL_NAME)\n",
        "\n",
        "def classify_inquiry(user_question):\n",
        "    prompt = f\"\"\"\n",
        "    Classify into: [Employment, General Information, Emergency Services, Tax Related]\n",
        "    Return ONLY the category name.\n",
        "    Question: {user_question}\n",
        "    Category:\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip().replace(\".\", \"\")\n",
        "\n",
        "def generate_social_post(topic, platform=\"Twitter\"):\n",
        "    prompt = f\"Write a brief {platform} post for Aurora Bay about: {topic}. Official tone, under 280 chars, one hashtag.\"\n",
        "    return model.generate_content(prompt).text.strip()\n",
        "\n",
        "# Classification Tests\n",
        "def test_class_emergency():\n",
        "    result = classify_inquiry(\"There is a bear on Main Street\")\n",
        "    assert \"Emergency\" in result\n",
        "\n",
        "def test_class_tax():\n",
        "    result = classify_inquiry(\"When is my property tax due?\")\n",
        "    assert \"Tax\" in result\n",
        "\n",
        "def test_class_employment():\n",
        "    result = classify_inquiry(\"Are there job openings at Parks Department?\")\n",
        "    assert \"Employment\" in result\n",
        "\n",
        "def test_class_general():\n",
        "    result = classify_inquiry(\"What time does the library close?\")\n",
        "    assert \"General\" in result\n",
        "\n",
        "# Social Media Tests\n",
        "def test_social_has_hashtag():\n",
        "    post = generate_social_post(\"Heavy snow expected\")\n",
        "    assert \"#\" in post\n",
        "\n",
        "def test_social_not_empty():\n",
        "    post = generate_social_post(\"Holiday hours\")\n",
        "    assert len(post) > 10\n",
        "\n",
        "def test_social_length():\n",
        "    post = generate_social_post(\"Library closed Monday\")\n",
        "    assert len(post) <= 280"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgrJDypuZtFt"
      },
      "source": [
        "## Cell 4: Run Unit Tests\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "Runs pytest with verbose output. Expected: 7 tests pass in 30-60 seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSoVKf_TZtFt",
        "outputId": "7c325c64-1817-495f-c6ba-9a217ffb2326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Unit Tests\n",
            "============================================================\n",
            "Testing classification and social media functions...\n",
            "\n",
            "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.12, pytest-9.0.1, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: langsmith-0.4.38, typeguard-4.4.4, anyio-4.11.0\n",
            "collected 7 items                                                              \u001b[0m\n",
            "\n",
            "test_challenge.py::test_class_emergency \u001b]9;4;2;0\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                           [ 14%]\u001b[0m\n",
            "test_challenge.py::test_class_tax \u001b]9;4;2;14\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                                 [ 28%]\u001b[0m\n",
            "test_challenge.py::test_class_employment \u001b]9;4;2;28\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                          [ 42%]\u001b[0m\n",
            "test_challenge.py::test_class_general \u001b]9;4;2;42\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                             [ 57%]\u001b[0m\n",
            "test_challenge.py::test_social_has_hashtag \u001b]9;4;2;57\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                        [ 71%]\u001b[0m\n",
            "test_challenge.py::test_social_not_empty \u001b]9;4;2;71\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                          [ 85%]\u001b[0m\n",
            "test_challenge.py::test_social_length \u001b]9;4;2;85\u001b\\\u001b[31mFAILED\u001b[0m\u001b[31m                             [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_____________________________ test_class_emergency _____________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df390e6f7a0>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df390c7bbc0>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {created_time:\"2025-12-02T23:34:00.178063715+00:00\", grpc_status:7, grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_class_emergency\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       result = classify_inquiry(\u001b[33m\"\u001b[39;49;00m\u001b[33mThere is a bear on Main Street\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:32: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:24: in classify_inquiry\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip().replace(\u001b[33m\"\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[31m\u001b[1m________________________________ test_class_tax ________________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df3904cb0e0>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df3877bbb80>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {created_time:\"2025-12-02T23:34:00.563603859+00:00\", grpc_status:7, grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_class_tax\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       result = classify_inquiry(\u001b[33m\"\u001b[39;49;00m\u001b[33mWhen is my property tax due?\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:36: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:24: in classify_inquiry\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip().replace(\u001b[33m\"\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[31m\u001b[1m____________________________ test_class_employment _____________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df390442cf0>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df38731b500>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {created_time:\"2025-12-02T23:34:00.938120216+00:00\", grpc_status:7, grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_class_employment\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       result = classify_inquiry(\u001b[33m\"\u001b[39;49;00m\u001b[33mAre there job openings at Parks Department?\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:40: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:24: in classify_inquiry\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip().replace(\u001b[33m\"\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[31m\u001b[1m______________________________ test_class_general ______________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df3904ca600>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df3873df800>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {created_time:\"2025-12-02T23:34:01.127173217+00:00\", grpc_status:7, grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_class_general\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       result = classify_inquiry(\u001b[33m\"\u001b[39;49;00m\u001b[33mWhat time does the library close?\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:44: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:24: in classify_inquiry\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip().replace(\u001b[33m\"\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"\\n    Classify into: [Employment, General Information, Emergency Servi...gory:\\n    \"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[31m\u001b[1m___________________________ test_social_has_hashtag ____________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"Write a brief Twitter post for Aurora Bay about: Heavy snow expected. ...ne hashtag.\"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df3904cbd40>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df38762f340>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {created_time:\"2025-12-02T23:34:01.336133045+00:00\", grpc_status:7, grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_social_has_hashtag\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       post = generate_social_post(\u001b[33m\"\u001b[39;49;00m\u001b[33mHeavy snow expected\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:49: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:28: in generate_social_post\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip()\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"Write a brief Twitter post for Aurora Bay about: Heavy snow expected. ...ne hashtag.\"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[31m\u001b[1m____________________________ test_social_not_empty _____________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"Write a brief Twitter post for Aurora Bay about: Holiday hours. Offici...ne hashtag.\"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df3904fb7a0>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df387552940>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\", grpc_status:7, created_time:\"2025-12-02T23:34:01.527971337+00:00\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_social_not_empty\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       post = generate_social_post(\u001b[33m\"\u001b[39;49;00m\u001b[33mHoliday hours\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:53: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:28: in generate_social_post\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip()\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"Write a brief Twitter post for Aurora Bay about: Holiday hours. Offici...ne hashtag.\"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[31m\u001b[1m______________________________ test_social_length ______________________________\u001b[0m\n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"Write a brief Twitter post for Aurora Bay about: Library closed Monday...ne hashtag.\"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:75: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:277: in __call__\n",
            "    \u001b[0mresponse, ignored_call = \u001b[96mself\u001b[39;49;00m._with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:332: in _with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m call.result(), call\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:440: in result\n",
            "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_interceptor.py\u001b[0m:315: in continuation\n",
            "    \u001b[0mresponse, call = \u001b[96mself\u001b[39;49;00m._thunk(new_method).with_call(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1198: in with_call\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _end_unary_response_blocking(state, call, \u001b[94mTrue\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "state = <grpc._channel._RPCState object at 0x7df3904c9e20>\n",
            "call = <grpc._cython.cygrpc.SegregatedCall object at 0x7df3904d7680>\n",
            "with_call = True, deadline = None\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_end_unary_response_blocking\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "        state: _RPCState,\u001b[90m\u001b[39;49;00m\n",
            "        call: cygrpc.SegregatedCall,\u001b[90m\u001b[39;49;00m\n",
            "        with_call: \u001b[96mbool\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "        deadline: Optional[\u001b[96mfloat\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "    ) -> Union[ResponseType, Tuple[ResponseType, grpc.Call]]:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m state.code \u001b[95mis\u001b[39;49;00m grpc.StatusCode.OK:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m with_call:\u001b[90m\u001b[39;49;00m\n",
            "                rendezvous = _MultiThreadedRendezvous(state, call, \u001b[94mNone\u001b[39;49;00m, deadline)\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response, rendezvous\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mreturn\u001b[39;49;00m state.response\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m _InactiveRpcError(state)  \u001b[90m# pytype: disable=not-instantiable\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tstatus = StatusCode.PERMISSION_DENIED\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdetails = \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:64.233.179.95:443 {grpc_message:\"Permission denied on resource project YOUR_PROJECT_ID.\", grpc_status:7, created_time:\"2025-12-02T23:34:01.731838364+00:00\"}\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           >\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m:1006: _InactiveRpcError\n",
            "\n",
            "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_social_length\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            ">       post = generate_social_post(\u001b[33m\"\u001b[39;49;00m\u001b[33mLibrary closed Monday\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:57: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mtest_challenge.py\u001b[0m:28: in generate_social_post\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m model.generate_content(prompt).text.strip()\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:710: in generate_content\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generate_content(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m:833: in _generate_content\n",
            "    \u001b[0mgapic_response = \u001b[96mself\u001b[39;49;00m._prediction_client.generate_content(request=request)\u001b[90m\u001b[39;49;00m\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m:2300: in generate_content\n",
            "    \u001b[0mresponse = rpc(\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m:131: in __call__\n",
            "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m wrapped_func(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (contents {\n",
            "  role: \"user\"\n",
            "  parts {\n",
            "    text: \"Write a brief Twitter post for Aurora Bay about: Library closed Monday...ne hashtag.\"\n",
            "  }\n",
            "}\n",
            "model: \"projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models/gemini-2.5-flash\"\n",
            ",)\n",
            "kwargs = {'metadata': [('x-goog-request-params', 'model=projects/YOUR_PROJECT_ID/locations/us-central1/publishers/google/models..._google_constructor_method+vertexai.generative_models.GenerativeModel.generate_content+environment+COLAB_ENTERPRISE')]}\n",
            "\n",
            "    \u001b[0m\u001b[37m@functools\u001b[39;49;00m.wraps(callable_)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92merror_remapped_callable\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m callable_(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m grpc.RpcError \u001b[94mas\u001b[39;49;00m exc:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m exceptions.from_grpc_error(exc) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96mexc\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           google.api_core.exceptions.PermissionDenied: 403 Permission denied on resource project YOUR_PROJECT_ID. [reason: \"CONSUMER_INVALID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           domain: \"googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"service\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"aiplatform.googleapis.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"containerInfo\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           metadata {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             key: \"consumer\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             value: \"projects/YOUR_PROJECT_ID\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , locale: \"en-US\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           message: \"Permission denied on resource project YOUR_PROJECT_ID.\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           , links {\u001b[0m\n",
            "\u001b[1m\u001b[31mE             description: \"Google developers console\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE             url: \"https://console.developers.google.com\"\u001b[0m\n",
            "\u001b[1m\u001b[31mE           }\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m:77: PermissionDenied\n",
            "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
            "../usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/models.py:52\n",
            "  /usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
            "    from google.cloud.aiplatform.utils import gcs_utils\n",
            "\n",
            "../usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433\n",
            "  /usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "    warning_logs.show_deprecation_warning()\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_class_emergency\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_class_tax\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_class_employment\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_class_general\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_social_has_hashtag\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_social_not_empty\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31mFAILED\u001b[0m test_challenge.py::\u001b[1mtest_social_length\u001b[0m - google.api_core.exceptions.PermissionDenied: 403 Permission denied on resou...\n",
            "\u001b[31m======================== \u001b[31m\u001b[1m7 failed\u001b[0m, \u001b[33m2 warnings\u001b[0m\u001b[31m in 6.88s\u001b[0m\u001b[31m =========================\u001b[0m\n",
            "\n",
            "Unit tests complete\n",
            "Next: Run Cell 5 for LLM evaluation\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Unit Tests\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Testing classification and social media functions...\")\n",
        "print()\n",
        "\n",
        "!pytest -v test_challenge.py\n",
        "\n",
        "print()\n",
        "print(\"Unit tests complete\")\n",
        "print(\"Next: Run Cell 5 for LLM evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izv5tt8eZtFt"
      },
      "source": [
        "## Cell 5: LLM Evaluation with Computed and Model-Based Metrics\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "**Two-Model Architecture:**\n",
        "- MODEL 1 (gemini-2.5-flash): Generates social media posts\n",
        "- MODEL 2 (Vertex AI Judge): Scores quality\n",
        "\n",
        "**Two Types of Metrics:**\n",
        "\n",
        "1. **Computed Metrics** (reference-based, deterministic):\n",
        "   - BLEU: N-gram overlap\n",
        "   - ROUGE-1, ROUGE-L: Word/sequence overlap\n",
        "\n",
        "2. **Model-Based Metrics** (semantic, uses Judge LLM):\n",
        "   - Coherence: Logical flow (1-5)\n",
        "   - Safety: Appropriateness (1-5)\n",
        "   - Fluency: Writing quality (1-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "bYP_PAWoZtFu",
        "outputId": "f50b3e89-0335-4f97-c218-6ea2e823d255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Evaluation with Multiple Metric Types\n",
            "============================================================\n",
            "\n",
            "Running evaluation (30-60 seconds)...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-40cfebc9-cb07-4bdf-9dc6-5639e776e175\" href=\"#view-view-vertex-resource-40cfebc9-cb07-4bdf-9dc6-5639e776e175\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-40cfebc9-cb07-4bdf-9dc6-5639e776e175');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-social-media-eval/runs?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-social-media-eval/runs?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-43302e49-3625-4b62-b84a-ddb3ebe646b2\" href=\"#view-view-vertex-resource-43302e49-3625-4b62-b84a-ddb3ebe646b2\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-43302e49-3625-4b62-b84a-ddb3ebe646b2');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-social-media-eval/runs/aurora-social-media-eval-8de1e3fe-75ff-42af-aa6b-cbadcedb694c?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-social-media-eval/runs/aurora-social-media-eval-8de1e3fe-75ff-42af-aa6b-cbadcedb694c?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.eval_task:Logging Eval Experiment metadata: {'prompt_template': '{instruction}', 'model_name': 'publishers/google/models/gemini-2.5-flash'}\n",
            "INFO:vertexai.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.evaluation._evaluation:Generating a total of 3 responses from Gemini model gemini-2.5-flash.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.73s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 3 responses are successfully generated from Gemini model gemini-2.5-flash.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 11.215114220001851 seconds.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 18 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:08<00:00,  2.08it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 18 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:8.654031955000391 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-5ca54a7f-44ad-4c90-845e-8c69c2523ab5\" href=\"#view-view-vertex-resource-5ca54a7f-44ad-4c90-845e-8c69c2523ab5\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-5ca54a7f-44ad-4c90-845e-8c69c2523ab5');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Evaluation Results\n",
            "============================================================\n",
            "\n",
            "COMPUTED METRICS\n",
            "------------------------------------------------------------\n",
            "BLEU:    0.003\n",
            "ROUGE-1: 0.043\n",
            "ROUGE-L: 0.034\n",
            "\n",
            "MODEL-BASED METRICS\n",
            "------------------------------------------------------------\n",
            "Coherence: 5.00 / 5.00\n",
            "Safety:    1.00 / 5.00\n",
            "Fluency:   5.00 / 5.00\n",
            "\n",
            "Test Cases: 3\n",
            "\n",
            "Next: Run Cell 6 for prompt comparison\n"
          ]
        }
      ],
      "source": [
        "print(\"LLM Evaluation with Multiple Metric Types\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "# Evaluation dataset\n",
        "eval_dataset = pd.DataFrame({\n",
        "    \"instruction\": [\n",
        "        \"Generate a social media post about heavy snow expected tonight\",\n",
        "        \"Generate a social media post about holiday hours for Town Hall\",\n",
        "        \"Generate a social media post about school closings due to weather\",\n",
        "    ],\n",
        "    \"reference\": [\n",
        "        \"Snow warning. Stay safe, avoid travel. Call 555-0100 for updates. #AuroraBay\",\n",
        "        \"Town Hall closed Dec 24-26. Emergency services available. Happy holidays! #AuroraBay\",\n",
        "        \"All schools closed today due to weather. Check aurora.gov for updates. #AuroraBay\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Metrics (both computed and model-based)\n",
        "metrics = [\n",
        "    \"bleu\",              # Computed\n",
        "    \"rouge_1\",           # Computed\n",
        "    \"rouge_l\",           # Computed\n",
        "    \"coherence\",         # Model-based\n",
        "    \"safety\",            # Model-based\n",
        "    \"fluency\",           # Model-based\n",
        "]\n",
        "\n",
        "task = EvalTask(\n",
        "    dataset=eval_dataset,\n",
        "    metrics=metrics,\n",
        "    experiment=\"aurora-social-media-eval\",\n",
        ")\n",
        "\n",
        "print(\"Running evaluation (30-60 seconds)...\")\n",
        "print()\n",
        "\n",
        "eval_result = task.evaluate(\n",
        "    model=model,\n",
        "    prompt_template=\"{instruction}\",\n",
        ")\n",
        "\n",
        "summary = eval_result.summary_metrics\n",
        "\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"Evaluation Results\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"COMPUTED METRICS\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"BLEU:    {summary.get('bleu/mean', 0):.3f}\")\n",
        "print(f\"ROUGE-1: {summary.get('rouge_1/mean', 0):.3f}\")\n",
        "print(f\"ROUGE-L: {summary.get('rouge_l/mean', 0):.3f}\")\n",
        "print()\n",
        "print(\"MODEL-BASED METRICS\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Coherence: {summary.get('coherence/mean', 0):.2f} / 5.00\")\n",
        "print(f\"Safety:    {summary.get('safety/mean', 0):.2f} / 5.00\")\n",
        "print(f\"Fluency:   {summary.get('fluency/mean', 0):.2f} / 5.00\")\n",
        "print()\n",
        "print(f\"Test Cases: {summary.get('row_count', 0)}\")\n",
        "print()\n",
        "print(\"Next: Run Cell 6 for prompt comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRQQTc96ZtFu"
      },
      "source": [
        "## Cell 6: Prompt Comparison - REQUIREMENT #5\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "**CRITICAL REQUIREMENT:** Use Google Evaluation API to **evaluate and compare** Gemini responses from **different prompts**.\n",
        "\n",
        "This cell demonstrates:\n",
        "1. Creating **three different prompt variants** for the same task\n",
        "2. Evaluating each variant using the **same metrics**\n",
        "3. **Comparing results** side-by-side\n",
        "4. **Analyzing which prompt performs better** and why\n",
        "\n",
        "### Three Prompt Strategies:\n",
        "\n",
        "**Variant A: Detailed Instructions**\n",
        "- Comprehensive requirements list\n",
        "- Examples provided\n",
        "- Clear tone specification\n",
        "\n",
        "**Variant B: Minimal/Concise**\n",
        "- Brief, high-level guidance\n",
        "- No examples\n",
        "- Tests if LLM can infer requirements\n",
        "\n",
        "**Variant C: Role-Based Persona**\n",
        "- Assigns specific role/expertise\n",
        "- Emphasizes professional standards\n",
        "- Tests if persona improves quality\n",
        "\n",
        "### Why Compare Prompts?\n",
        "\n",
        "Prompt engineering is iterative. Different approaches yield different results. Metrics reveal which strategy works best through data-driven optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0cmId95IZtFu",
        "outputId": "4f7e108c-8296-4b6c-cfb8-08aa99fcdc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Comparison Experiment - Requirement #5\n",
            "============================================================\n",
            "\n",
            "Comparing THREE different prompt strategies\n",
            "\n",
            "Prompt Variants:\n",
            "  A: Detailed with requirements and examples\n",
            "  B: Minimal, concise instructions\n",
            "  C: Role-based persona with expertise\n",
            "\n",
            "Evaluating each prompt variant...\n",
            "This will take 2-3 minutes (3 variants x 3 test cases)\n",
            "\n",
            "Evaluating Variant A_Detailed...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-bc2425fe-558e-4c37-98a2-4de0b8ba1e4e\" href=\"#view-view-vertex-resource-bc2425fe-558e-4c37-98a2-4de0b8ba1e4e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-bc2425fe-558e-4c37-98a2-4de0b8ba1e4e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-a-detailed/runs?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-a-detailed/runs?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-8b6f470c-1750-40bc-8816-e2c978ab7079\" href=\"#view-view-vertex-resource-8b6f470c-1750-40bc-8816-e2c978ab7079\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-8b6f470c-1750-40bc-8816-e2c978ab7079');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-a-detailed/runs/aurora-prompt-comparison-a-detailed-dc1ca548-f422-440f-96ae-5bbca7f3fe19?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-a-detailed/runs/aurora-prompt-comparison-a-detailed-dc1ca548-f422-440f-96ae-5bbca7f3fe19?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.eval_task:Logging Eval Experiment metadata: {'prompt_template': '\\nYou are the social media manager for the town of Aurora Bay.\\n\\nWrite a short Twitter post about: {topic}\\n\\nREQUIREMENTS:\\n- Tone: Official but friendly and helpful\\n- Length: Concise (under 280 characters)\\n- Include exactly ONE relevant hashtag\\n- Be informative and actionable\\n- Avoid fear-mongering\\n\\nEXAMPLES:\\n- Snow emergency declared. Parking ban 8pm-6am. Check aurora.gov for updates. #AuroraBay\\n- Libraries closed Monday for MLK Day. Digital services available 24/7. #AuroraBay\\n', 'model_name': 'publishers/google/models/gemini-2.5-flash'}\n",
            "INFO:vertexai.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.evaluation._evaluation:Generating a total of 3 responses from Gemini model gemini-2.5-flash.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.52s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 3 responses are successfully generated from Gemini model gemini-2.5-flash.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 4.576765454999986 seconds.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 18 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:08<00:00,  2.20it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 18 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:8.20896655800243 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-3bbb9fdd-deca-4b77-9d9f-3e3e2409884c\" href=\"#view-view-vertex-resource-3bbb9fdd-deca-4b77-9d9f-3e3e2409884c\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-3bbb9fdd-deca-4b77-9d9f-3e3e2409884c');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Completed: A_Detailed\n",
            "\n",
            "Evaluating Variant B_Minimal...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-dffb1dbd-8340-4dae-ae4e-5b1350432877\" href=\"#view-view-vertex-resource-dffb1dbd-8340-4dae-ae4e-5b1350432877\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-dffb1dbd-8340-4dae-ae4e-5b1350432877');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-b-minimal/runs?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-b-minimal/runs?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-6e586273-2c40-44fd-9e76-e5722ec5806e\" href=\"#view-view-vertex-resource-6e586273-2c40-44fd-9e76-e5722ec5806e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-6e586273-2c40-44fd-9e76-e5722ec5806e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-b-minimal/runs/aurora-prompt-comparison-b-minimal-fca65375-95fc-4fc0-82de-8f372a94ec6b?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-b-minimal/runs/aurora-prompt-comparison-b-minimal-fca65375-95fc-4fc0-82de-8f372a94ec6b?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.eval_task:Logging Eval Experiment metadata: {'prompt_template': '\\nWrite a brief Twitter post for Aurora Bay town government about: {topic}\\nKeep it professional, informative, and under 280 characters. Include one hashtag.\\n', 'model_name': 'publishers/google/models/gemini-2.5-flash'}\n",
            "INFO:vertexai.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.evaluation._evaluation:Generating a total of 3 responses from Gemini model gemini-2.5-flash.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.65s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 3 responses are successfully generated from Gemini model gemini-2.5-flash.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 4.965044444001251 seconds.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 18 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:08<00:00,  2.18it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 18 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:8.269255238999904 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-91afc701-2099-4015-832f-98be8e8978cd\" href=\"#view-view-vertex-resource-91afc701-2099-4015-832f-98be8e8978cd\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-91afc701-2099-4015-832f-98be8e8978cd');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Completed: B_Minimal\n",
            "\n",
            "Evaluating Variant C_Persona...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-c39b116b-8639-4b3c-8c61-e0dd6c303347\" href=\"#view-view-vertex-resource-c39b116b-8639-4b3c-8c61-e0dd6c303347\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-c39b116b-8639-4b3c-8c61-e0dd6c303347');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-c-persona/runs?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-c-persona/runs?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-7c8493c7-d5df-4089-97e5-39b91ada82bc\" href=\"#view-view-vertex-resource-7c8493c7-d5df-4089-97e5-39b91ada82bc\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-7c8493c7-d5df-4089-97e5-39b91ada82bc');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-c-persona/runs/aurora-prompt-comparison-c-persona-aa59a9d9-eced-4451-9d04-f0d5ce2aeeae?project=qwiklabs-gcp-03-ba43f2730b93');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-comparison-c-persona/runs/aurora-prompt-comparison-c-persona-aa59a9d9-eced-4451-9d04-f0d5ce2aeeae?project=qwiklabs-gcp-03-ba43f2730b93', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.eval_task:Logging Eval Experiment metadata: {'prompt_template': '\\nYou are an experienced public affairs officer for Aurora Bay with 10 years of crisis communication experience.\\nYour posts are known for being calm, clear, and action-oriented.\\n\\nWrite a Twitter post about: {topic}\\n\\nUse your professional judgment to:\\n- Convey essential information\\n- Maintain appropriate tone\\n- Keep under 280 characters\\n- Include relevant hashtag\\n', 'model_name': 'publishers/google/models/gemini-2.5-flash'}\n",
            "INFO:vertexai.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.evaluation._evaluation:Generating a total of 3 responses from Gemini model gemini-2.5-flash.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.40s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 3 responses are successfully generated from Gemini model gemini-2.5-flash.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 4.212608131998422 seconds.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 18 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:09<00:00,  1.82it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 18 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:9.920351061002293 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-d4c4b1c7-3e3e-488b-89f8-556580f2a2ab\" href=\"#view-view-vertex-resource-d4c4b1c7-3e3e-488b-89f8-556580f2a2ab\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-d4c4b1c7-3e3e-488b-89f8-556580f2a2ab');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Completed: C_Persona\n",
            "\n",
            "\n",
            "============================================================\n",
            "Prompt Comparison Results\n",
            "============================================================\n",
            "\n",
            "COMPUTED METRICS\n",
            "------------------------------------------------------------\n",
            "Metric             Variant A    Variant B    Variant C\n",
            "------------------------------------------------------------\n",
            "bleu                  0.047         0.087 *       0.047  \n",
            "rouge_1               0.295         0.405 *       0.333  \n",
            "rouge_l               0.198         0.329 *       0.288  \n",
            "\n",
            "MODEL-BASED METRICS\n",
            "------------------------------------------------------------\n",
            "Metric             Variant A    Variant B    Variant C\n",
            "------------------------------------------------------------\n",
            "coherence              5.00 *        5.00 *        5.00 *\n",
            "safety                 1.00 *        1.00 *        1.00 *\n",
            "fluency                5.00 *        5.00 *        5.00 *\n",
            "\n",
            "* = Best performer for this metric\n",
            "\n",
            "============================================================\n",
            "Analysis and Recommendations\n",
            "============================================================\n",
            "\n",
            "Metric Wins by Variant:\n",
            "  A_Detailed: 3/6 metrics\n",
            "  B_Minimal: 6/6 metrics\n",
            "  C_Persona: 3/6 metrics\n",
            "\n",
            "Overall Best Performer: B_Minimal\n",
            "\n",
            "Key Findings:\n",
            "\n",
            "  Minimal prompts performed best.\n",
            "  LLM has strong baseline understanding\n",
            "  Simpler prompts are more maintainable\n",
            "\n",
            "Recommendation for Production:\n",
            "  Use Variant B_Minimal for Aurora Bay social media posts\n",
            "  Achieved highest scores across 6 of 6 metrics\n",
            "\n",
            "============================================================\n",
            "Prompt Comparison Complete - Requirement #5 SATISFIED\n",
            "============================================================\n",
            "\n",
            "Next: Run Cell 7 for submission checklist\n"
          ]
        }
      ],
      "source": [
        "print(\"Prompt Comparison Experiment - Requirement #5\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"Comparing THREE different prompt strategies\")\n",
        "print()\n",
        "\n",
        "# Create three different prompt templates\n",
        "prompt_variants = {\n",
        "    \"A_Detailed\": \"\"\"\n",
        "You are the social media manager for the town of Aurora Bay.\n",
        "\n",
        "Write a short Twitter post about: {topic}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Tone: Official but friendly and helpful\n",
        "- Length: Concise (under 280 characters)\n",
        "- Include exactly ONE relevant hashtag\n",
        "- Be informative and actionable\n",
        "- Avoid fear-mongering\n",
        "\n",
        "EXAMPLES:\n",
        "- Snow emergency declared. Parking ban 8pm-6am. Check aurora.gov for updates. #AuroraBay\n",
        "- Libraries closed Monday for MLK Day. Digital services available 24/7. #AuroraBay\n",
        "\"\"\",\n",
        "\n",
        "    \"B_Minimal\": \"\"\"\n",
        "Write a brief Twitter post for Aurora Bay town government about: {topic}\n",
        "Keep it professional, informative, and under 280 characters. Include one hashtag.\n",
        "\"\"\",\n",
        "\n",
        "    \"C_Persona\": \"\"\"\n",
        "You are an experienced public affairs officer for Aurora Bay with 10 years of crisis communication experience.\n",
        "Your posts are known for being calm, clear, and action-oriented.\n",
        "\n",
        "Write a Twitter post about: {topic}\n",
        "\n",
        "Use your professional judgment to:\n",
        "- Convey essential information\n",
        "- Maintain appropriate tone\n",
        "- Keep under 280 characters\n",
        "- Include relevant hashtag\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "print(\"Prompt Variants:\")\n",
        "print(\"  A: Detailed with requirements and examples\")\n",
        "print(\"  B: Minimal, concise instructions\")\n",
        "print(\"  C: Role-based persona with expertise\")\n",
        "print()\n",
        "\n",
        "# Same dataset for all variants\n",
        "eval_dataset = pd.DataFrame({\n",
        "    \"topic\": [\n",
        "        \"heavy snow expected tonight\",\n",
        "        \"holiday hours for Town Hall\",\n",
        "        \"school closings due to weather\",\n",
        "    ],\n",
        "    \"reference\": [\n",
        "        \"Snow warning. Stay safe, avoid travel. Call 555-0100 for updates. #AuroraBay\",\n",
        "        \"Town Hall closed Dec 24-26. Emergency services available. Happy holidays! #AuroraBay\",\n",
        "        \"All schools closed today due to weather. Check aurora.gov for updates. #AuroraBay\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Same metrics for all variants\n",
        "metrics = [\"bleu\", \"rouge_1\", \"rouge_l\", \"coherence\", \"safety\", \"fluency\"]\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "print(\"Evaluating each prompt variant...\")\n",
        "print(\"This will take 2-3 minutes (3 variants x 3 test cases)\")\n",
        "print()\n",
        "\n",
        "# Evaluate each variant\n",
        "for variant_name, prompt_template in prompt_variants.items():\n",
        "    print(f\"Evaluating Variant {variant_name}...\")\n",
        "\n",
        "    task = EvalTask(\n",
        "        dataset=eval_dataset,\n",
        "        metrics=metrics,\n",
        "        experiment=f\"aurora-prompt-comparison-{variant_name.lower().replace('_', '-')}\",\n",
        "    )\n",
        "\n",
        "    eval_result = task.evaluate(\n",
        "        model=model,\n",
        "        prompt_template=prompt_template,\n",
        "    )\n",
        "\n",
        "    results[variant_name] = eval_result.summary_metrics\n",
        "    print(f\"  Completed: {variant_name}\")\n",
        "    print()\n",
        "\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"Prompt Comparison Results\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "# Display side-by-side comparison\n",
        "print(\"COMPUTED METRICS\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Metric':<15} {'Variant A':>12} {'Variant B':>12} {'Variant C':>12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for metric in ['bleu', 'rouge_1', 'rouge_l']:\n",
        "    a_val = results['A_Detailed'].get(f'{metric}/mean', 0)\n",
        "    b_val = results['B_Minimal'].get(f'{metric}/mean', 0)\n",
        "    c_val = results['C_Persona'].get(f'{metric}/mean', 0)\n",
        "\n",
        "    best_val = max(a_val, b_val, c_val)\n",
        "    a_mark = \" *\" if a_val == best_val else \"\"\n",
        "    b_mark = \" *\" if b_val == best_val else \"\"\n",
        "    c_mark = \" *\" if c_val == best_val else \"\"\n",
        "\n",
        "    print(f\"{metric:<15} {a_val:>11.3f}{a_mark:<2} {b_val:>11.3f}{b_mark:<2} {c_val:>11.3f}{c_mark:<2}\")\n",
        "\n",
        "print()\n",
        "print(\"MODEL-BASED METRICS\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Metric':<15} {'Variant A':>12} {'Variant B':>12} {'Variant C':>12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for metric in ['coherence', 'safety', 'fluency']:\n",
        "    a_val = results['A_Detailed'].get(f'{metric}/mean', 0)\n",
        "    b_val = results['B_Minimal'].get(f'{metric}/mean', 0)\n",
        "    c_val = results['C_Persona'].get(f'{metric}/mean', 0)\n",
        "\n",
        "    best_val = max(a_val, b_val, c_val)\n",
        "    a_mark = \" *\" if a_val == best_val else \"\"\n",
        "    b_mark = \" *\" if b_val == best_val else \"\"\n",
        "    c_mark = \" *\" if c_val == best_val else \"\"\n",
        "\n",
        "    print(f\"{metric:<15} {a_val:>11.2f}{a_mark:<2} {b_val:>11.2f}{b_mark:<2} {c_val:>11.2f}{c_mark:<2}\")\n",
        "\n",
        "print()\n",
        "print(\"* = Best performer for this metric\")\n",
        "print()\n",
        "\n",
        "# Calculate overall winner\n",
        "print(\"=\" * 60)\n",
        "print(\"Analysis and Recommendations\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "wins = {'A_Detailed': 0, 'B_Minimal': 0, 'C_Persona': 0}\n",
        "all_metrics = ['bleu', 'rouge_1', 'rouge_l', 'coherence', 'safety', 'fluency']\n",
        "\n",
        "for metric in all_metrics:\n",
        "    a_val = results['A_Detailed'].get(f'{metric}/mean', 0)\n",
        "    b_val = results['B_Minimal'].get(f'{metric}/mean', 0)\n",
        "    c_val = results['C_Persona'].get(f'{metric}/mean', 0)\n",
        "    best_val = max(a_val, b_val, c_val)\n",
        "\n",
        "    if a_val == best_val:\n",
        "        wins['A_Detailed'] += 1\n",
        "    if b_val == best_val:\n",
        "        wins['B_Minimal'] += 1\n",
        "    if c_val == best_val:\n",
        "        wins['C_Persona'] += 1\n",
        "\n",
        "print(\"Metric Wins by Variant:\")\n",
        "for variant, count in wins.items():\n",
        "    print(f\"  {variant}: {count}/{len(all_metrics)} metrics\")\n",
        "print()\n",
        "\n",
        "winner = max(wins, key=wins.get)\n",
        "print(f\"Overall Best Performer: {winner}\")\n",
        "print()\n",
        "\n",
        "print(\"Key Findings:\")\n",
        "print()\n",
        "\n",
        "if winner == 'A_Detailed':\n",
        "    print(\"  Detailed instructions with examples performed best.\")\n",
        "    print(\"  Clear requirements reduce ambiguity\")\n",
        "    print(\"  Examples provide concrete guidance\")\n",
        "elif winner == 'B_Minimal':\n",
        "    print(\"  Minimal prompts performed best.\")\n",
        "    print(\"  LLM has strong baseline understanding\")\n",
        "    print(\"  Simpler prompts are more maintainable\")\n",
        "else:\n",
        "    print(\"  Role-based persona performed best.\")\n",
        "    print(\"  Expertise framing improves judgment\")\n",
        "    print(\"  Professional context enhances quality\")\n",
        "\n",
        "print()\n",
        "print(\"Recommendation for Production:\")\n",
        "print(f\"  Use Variant {winner} for Aurora Bay social media posts\")\n",
        "print(f\"  Achieved highest scores across {wins[winner]} of {len(all_metrics)} metrics\")\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"Prompt Comparison Complete - Requirement #5 SATISFIED\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"Next: Run Cell 7 for submission checklist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JvVSR7DZtFu"
      },
      "source": [
        "## Cell 7: Submission Checklist\n",
        "\n",
        "### What is happening here?\n",
        "\n",
        "Final checklist and submission instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoGH_AbKZtFu",
        "outputId": "05890aa4-ced0-4c23-d0e6-f4093efd630f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Challenge Three: Submission Checklist\n",
            "============================================================\n",
            "\n",
            "[X] Installed pytest and evaluation libraries\n",
            "[X] Defined classify_inquiry() function\n",
            "[X] Defined generate_social_post() function\n",
            "[X] Created test_challenge.py file\n",
            "[X] Ran unit tests with pytest\n",
            "[X] Ran LLM evaluation with computed metrics\n",
            "[X] Ran LLM evaluation with model-based metrics\n",
            "[X] Compared different prompts using Evaluation API\n",
            "[X] Identified best-performing prompt variant\n",
            "[ ] Download notebook (.ipynb)\n",
            "[ ] Create GitHub repository\n",
            "[ ] Upload notebook to GitHub\n",
            "[ ] Share GitHub link with instructor\n",
            "\n",
            "============================================================\n",
            "Requirements Coverage - ALL COMPLETE\n",
            "============================================================\n",
            "\n",
            "[X] Requirement 1: Jupyter Notebook (Colab Enterprise compatible)\n",
            "[X] Requirement 2: Classification function with 4 categories\n",
            "[X] Requirement 3: Social media generation function\n",
            "[X] Requirement 4: Unit tests with pytest\n",
            "[X] Requirement 5: Evaluate and COMPARE different prompts\n",
            "[X] Requirement 6: Ready for GitHub submission\n",
            "\n",
            "============================================================\n",
            "GitHub Submission Steps\n",
            "============================================================\n",
            "\n",
            "1. Download this notebook\n",
            "   File > Download > Download .ipynb\n",
            "\n",
            "2. Create GitHub repository\n",
            "   Name: challenge-03-testing-evaluation\n",
            "\n",
            "3. Upload files\n",
            "   - challenge_03_complete.ipynb\n",
            "   - README.md with project description\n",
            "\n",
            "4. Submit repository URL to instructor\n",
            "\n",
            "============================================================\n",
            "Challenge Three Complete\n",
            "============================================================\n",
            "\n",
            "Successfully demonstrated:\n",
            "  Two-model architecture understanding\n",
            "  Production-quality LLM functions\n",
            "  Comprehensive testing strategies\n",
            "  Multiple evaluation metric types\n",
            "  Scientific prompt comparison\n",
            "  Software engineering best practices\n",
            "\n",
            "COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"Challenge Three: Submission Checklist\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "checklist = [\n",
        "    (\"DONE\", \"Installed pytest and evaluation libraries\"),\n",
        "    (\"DONE\", \"Defined classify_inquiry() function\"),\n",
        "    (\"DONE\", \"Defined generate_social_post() function\"),\n",
        "    (\"DONE\", \"Created test_challenge.py file\"),\n",
        "    (\"DONE\", \"Ran unit tests with pytest\"),\n",
        "    (\"DONE\", \"Ran LLM evaluation with computed metrics\"),\n",
        "    (\"DONE\", \"Ran LLM evaluation with model-based metrics\"),\n",
        "    (\"DONE\", \"Compared different prompts using Evaluation API\"),\n",
        "    (\"DONE\", \"Identified best-performing prompt variant\"),\n",
        "    (\"TODO\", \"Download notebook (.ipynb)\"),\n",
        "    (\"TODO\", \"Create GitHub repository\"),\n",
        "    (\"TODO\", \"Upload notebook to GitHub\"),\n",
        "    (\"TODO\", \"Share GitHub link with instructor\"),\n",
        "]\n",
        "\n",
        "for status, item in checklist:\n",
        "    marker = \"[X]\" if status == \"DONE\" else \"[ ]\"\n",
        "    print(f\"{marker} {item}\")\n",
        "\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"Requirements Coverage - ALL COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"[X] Requirement 1: Jupyter Notebook (Colab Enterprise compatible)\")\n",
        "print(\"[X] Requirement 2: Classification function with 4 categories\")\n",
        "print(\"[X] Requirement 3: Social media generation function\")\n",
        "print(\"[X] Requirement 4: Unit tests with pytest\")\n",
        "print(\"[X] Requirement 5: Evaluate and COMPARE different prompts\")\n",
        "print(\"[X] Requirement 6: Ready for GitHub submission\")\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"GitHub Submission Steps\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"1. Download this notebook\")\n",
        "print(\"   File > Download > Download .ipynb\")\n",
        "print()\n",
        "print(\"2. Create GitHub repository\")\n",
        "print(\"   Name: challenge-03-testing-evaluation\")\n",
        "print()\n",
        "print(\"3. Upload files\")\n",
        "print(\"   - challenge_03_complete.ipynb\")\n",
        "print(\"   - README.md with project description\")\n",
        "print()\n",
        "print(\"4. Submit repository URL to instructor\")\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"Challenge Three Complete\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "print(\"Successfully demonstrated:\")\n",
        "print(\"  Two-model architecture understanding\")\n",
        "print(\"  Production-quality LLM functions\")\n",
        "print(\"  Comprehensive testing strategies\")\n",
        "print(\"  Multiple evaluation metric types\")\n",
        "print(\"  Scientific prompt comparison\")\n",
        "print(\"  Software engineering best practices\")\n",
        "print()\n",
        "print(\"COMPLETE\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}